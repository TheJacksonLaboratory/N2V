{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen import CorpusTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = CorpusTransformer(\n",
    "    apply_stemming=False,\n",
    "    verbose=False,\n",
    "    remove_stop_words=False,\n",
    "    remove_punctuation=False,\n",
    "    min_word_length=0,\n",
    "    to_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"This is a GENERIC text tokenizer and is only useful for basic examples\",\n",
    "    \"as in any advanced settings there will be need for a custom tokenizer.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 1, 5, 6, 2, 7, 0, 8, 9, 3, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 3, 1, 21, 2]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(text)\n",
    "transformer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('this', 1),\n",
       "             ('is', 2),\n",
       "             ('a', 2),\n",
       "             ('generic', 1),\n",
       "             ('text', 1),\n",
       "             ('tokenizer', 2),\n",
       "             ('and', 1),\n",
       "             ('only', 1),\n",
       "             ('useful', 1),\n",
       "             ('for', 2),\n",
       "             ('basic', 1),\n",
       "             ('examples', 1),\n",
       "             ('as', 1),\n",
       "             ('in', 1),\n",
       "             ('any', 1),\n",
       "             ('advanced', 1),\n",
       "             ('settings', 1),\n",
       "             ('there', 1),\n",
       "             ('will', 1),\n",
       "             ('be', 1),\n",
       "             ('need', 1),\n",
       "             ('custom', 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer._tokenizer.word_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
