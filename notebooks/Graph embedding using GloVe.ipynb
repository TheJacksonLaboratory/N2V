{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding using GloVe\n",
    "[GloVe embeddings are global embeddings](https://www.aclweb.org/anthology/D14-1162.pdf_). A GloVe model tries to predict, given two elements out of the corpus vocabulary, their cooccurrence frequency.\n",
    "\n",
    "GloVe model do not scale nicely with the graph size, as the cooccurrence matrix requires to be fully rendered (clearly as a CSR) before the model is trained, hence occupying a significant memory portion on huge graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto # Import needed to avoid TensorFlow warnings and general useless infos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the ppi graph from the repository as a weighted undirected graph.\n",
    "\n",
    "To load the graph we are using the sister package of Embiggen called [Ensmallen](https://github.com/LucaCappelletti94/ensmallen_graph). Ensmallen is a Rust library with python bindings to handle processing of graph files and preprocessing of data for quickly training embedding models.\n",
    "\n",
    "It also supports numerous utilities that can be helpful when dealing with graphs, such as ways to compute holdouts of different kinds on the graph edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "graph = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"../data/ppi/edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    weights_column=\"weight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing, we print a short report showing all the avalable graph details, including the number of edges, nodes, trap nodes and both the connected components and the strongly connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_number': '17185',\n",
       " 'bidirectional_percentage': '1',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'traps_rate': '0',\n",
       " 'singleton_nodes': '0',\n",
       " 'edges_number': '588748',\n",
       " 'degrees_mode': '1',\n",
       " 'connected_components_number': '181',\n",
       " 'selfloops_percentage': '0',\n",
       " 'density': '0.001993564869255138',\n",
       " 'is_directed': 'false',\n",
       " 'unique_node_types_number': '0',\n",
       " 'degrees_mean': '34.25941227814955',\n",
       " 'strongly_connected_components_number': '181',\n",
       " 'degrees_median': '11'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training and validation partitions\n",
    "To execute the embedding of the graph with the goal of running Link Prediction on the obtained vectors (after having obtained the edges embeddings from the nodes embeddings), we need to create two partitions of the graph. One containing the training set edges, which is left connected (if the initial graph was connected) or at least with the same number of connected components are the initial graph, and one containing the validation set edges, which may not be connected.\n",
    "\n",
    "The requirement for connectivity is stated in the seminal work from [Leskovec et al.](https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf) but we have no proofs, currently, that actually changes performance of the embedding.\n",
    "\n",
    "#### Limitation in using connected training set\n",
    "Creating holdouts in this fashion allows us to estimate the real-world model performance only for cases when the new edges that we intend to predict are part of the existing graph components and do not ever connect separated components of the graph.\n",
    "\n",
    "### Why not simply using the complete graph in the embedding process\n",
    "If we were to use the complete graph during the embedding process, we would end up encoding the answers for the Link Prediction problem into the embedding for both the training and validation partitions, hence adding a positive bias that would inflate the performance of the models.\n",
    "\n",
    "**NB: the entire graph should be used for embeddings when the task will be a node-label prediction task, when no nodes labels are taken in consideration in any shape of form during the random walks.**\n",
    "\n",
    "### The inevitable presence of false negatives in the embedding training process\n",
    "\n",
    "In the training set of the model there will be inevitably some false negatives. These originates from the sampling of random edges as negatives.\n",
    "\n",
    "In Binary SkipGram, meaning the models that receive two words and tries to predict if the connection exists or not, this sampling is needed to produce negative examples so that the network don't overfit returning always true.\n",
    "\n",
    "In Categorical-Models, such as CBOW and non-binary SkipGram, meaning the one which either receive the context and tries to predict the central word, or receives the word and tries to predict the context, the sample is only present if they use the [Noise Contrastive Estimation (NCE)](https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss) loss which, instead of computing the softmax and the categorical cross entropy, samples a random number of categories per batch and applies, to the choosen outputs, a sigmoid activation function, hence computing the logits, and then computes the binary cross-entropy for each of them. Finally the losses are summed to obtain the final loss.\n",
    "\n",
    "In this case, the problem of false negatives araise from the fact that during the computation of the NCE loss, in order to have negative examples, the function samples random words to use as wrong predictions for the given context. This of course could create false negatives if the choosen random word appears in another batch with the same context, and can be easily shown that this leads to sampling potentialy false negative edges.\n",
    "\n",
    "The only method to avoid these is to do the **embedding on the whole graph** which create a positive bias for the link-prediction.\n",
    "This bias is formed because the embedding is encoding the data by learning which nodes are close and **thus is encoding the link prediction of the validation set and invalidating the link-prediction performances**.\n",
    "\n",
    "Therefore, the only way is to accept the false negatives since in a real world application the link prediction is used as an oracle to explore new possible edges. \n",
    "\n",
    "#### Additional false positives relative to collisions with known training edges\n",
    "For the same sampling issue, there will be also collisions with the training edges. This should be a lesser problem though, as the model will be more likely to see the positive label for any given training edge that the collision, though to the strong imbalance between the number of available training edges and the complete number of edges.\n",
    "\n",
    "This imbalance, in PPI, is around 1 positive edge to 1000 negative edges.\n",
    "\n",
    "### Early stopping criterion for the embedding process\n",
    "For the early stopping criterion used in the embedding process, during the model selection (the procedure where we select the optimal $p$, $q$ and embedding size parameters, amongs others) we can use the validation partition to stop the training early (hence early stopping) when a metric representing of the quality of the embedding stops improving.\n",
    "\n",
    "Since the validation set is not connected we cannot diretly use the validation set for th early stopping, as it would not allow us to create random walks that represent the graph structure.\n",
    "\n",
    "For this reason we need to use the entire training+validation set for the early stopping. This will allow us to compute random walks that should be representative of the graph structure.\n",
    "\n",
    "The validation edges are never fed into the training model as positives, but are only used in the context of the early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the graph into the two edge partitions\n",
    "As described above, we split the graphs into two partitions:\n",
    "\n",
    "- The training component, with the same number of components as the initial graph\n",
    "- The validation component, that may have more components than the initial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = graph.connected_holdout(42, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are check that are not necessary, but are offered as sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert graph > training\n",
    "assert graph > validation\n",
    "assert (training + validation).contains(graph)\n",
    "assert graph.contains(training + validation)\n",
    "assert not training.overlaps(validation)\n",
    "assert not validation.overlaps(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considered parameters\n",
    "We are going to use the following parameters:\n",
    "\n",
    "- **Walk lengths:** $100$ nodes.\n",
    "- **Batch size:** $2^{7} = 128$ walks per batch.\n",
    "- **Walk iterations:** $20$ iterations on the graph.\n",
    "- **Window size:** $4$ nodes, meaning $4$ on the left and $4$ on the right of the center nodes. Consider that the first *window_size* values on the left and the right of the walks will be trimmed.\n",
    "- **Return weight, inverse of $p$:** $1.0$.\n",
    "- **Explore weight, inverse of $q$:** $1.0$.\n",
    "- **Embedding size:** $100$.\n",
    "- **Optimizer:** [Nadam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam).\n",
    "- **Early stopping parameters:** We are going to use an Early Stopping criterion on the *validation loss*, with patience $5$ and delta $0.0001$.\n",
    "- **Epochs:** The model will be trained up to $1000$ epochs.\n",
    "- **Learning rate:** since tipically the loss function is quite convex for the embedding problem, we can use a relatively higher learning rate. We are going to us $0.1$ for this example, to get to a faster convergence: this might lead to skipping some better minima that might be identified with a lower learning rate, such as the default one which is $0.0001$.\n",
    "- **Glove loss alpha:** 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length=100\n",
    "batch_size=2**20\n",
    "iterations=20\n",
    "window_size=4\n",
    "p=1.0\n",
    "q=1.0\n",
    "embedding_size=100\n",
    "patience=5\n",
    "delta=0.0001\n",
    "epochs=1000\n",
    "learning_rate=0.1\n",
    "glove_alpha=0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the training and validation Keras sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_contexts, train_labels = training.cooccurence_matrix(\n",
    "    walk_length,\n",
    "    window_size=window_size,\n",
    "    iterations=iterations,\n",
    "    return_weight=1/p,\n",
    "    explore_weight=1/q\n",
    ")\n",
    "\n",
    "valid_words, valid_contexts, valid_labels = graph.cooccurence_matrix(\n",
    "    walk_length,\n",
    "    window_size=window_size,\n",
    "    iterations=iterations,\n",
    "    return_weight=1/p,\n",
    "    explore_weight=1/q\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GloVe model\n",
    "We are going to setup the model to use, if available, multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GloVe\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_embedding (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       1718500     words_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       1718500     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         17185       words_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         17185       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 1)         0           dot[0][0]                        \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 3,471,370\n",
      "Trainable params: 3,471,370\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.distribute import MirroredStrategy\n",
    "from embiggen import GloVe\n",
    "\n",
    "strategy = MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = GloVe(\n",
    "        vocabulary_size=training.get_nodes_number(),\n",
    "        embedding_size=embedding_size,\n",
    "        alpha=glove_alpha\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 11s 418ms/step - loss: 0.0349 - val_loss: 0.0373\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0331 - val_loss: 0.0353\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 9s 363ms/step - loss: 0.0312 - val_loss: 0.0332\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0293 - val_loss: 0.0311\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 10s 368ms/step - loss: 0.0256 - val_loss: 0.0270\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0238 - val_loss: 0.0250\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0221 - val_loss: 0.0233\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0205 - val_loss: 0.0216\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0191 - val_loss: 0.0201\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0178 - val_loss: 0.0188\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 10s 370ms/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 9s 357ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 10s 365ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 9s 357ms/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 9s 363ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 9s 365ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 9s 354ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 9s 363ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 10s 368ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 9s 352ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 10s 376ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 9s 360ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 9s 354ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 9s 357ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 9s 363ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 9s 352ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 9s 359ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 9s 356ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 9s 365ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 9s 355ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0036 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "history = model.fit(\n",
    "    (train_words, train_contexts), train_labels,\n",
    "    validation_data=((valid_words, valid_contexts), valid_labels),\n",
    "    epochs=1000,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            \"val_loss\",\n",
    "            min_delta=delta,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model weights\n",
    "We save the obtained model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{model.name}_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the training history\n",
    "We can visualize the performance of the model during the training process as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_keras_history import plot_history\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some hickups in the plot of the history if the model is reloaded from stored weights: [this is a known Keras issue](https://github.com/keras-team/keras/issues/4875) and is not related to either the holdouts used or the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the obtained embeddings\n",
    "Finally we save our hard earned model embeddings. In another notebook we will show how to do link prediction on the obtained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(f\"{model.name}_embedding.npy\", model.embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
