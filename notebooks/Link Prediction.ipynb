{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS, TUTORIAL NOT COMPLETE\n",
    "\n",
    "# Link Prediction on embeddings\n",
    "The link prediction problem consists in trying to predict the edges that actually exists in the graph.\n",
    "\n",
    "In our implementation we can execute training on big graphs lazily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen import GraphTransformer\n",
    "from ensmallen_graph import EnsmallenGraph\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import silence_tensorflow.auto\n",
    "import numpy as np\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from plot_keras_history import plot_history\n",
    "from plot_keras_history.utils import chain_histories\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the graphs\n",
    "We load the ppi graph as a weighted undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = EnsmallenGraph.from_csv(\n",
    "    edge_path=\"../data/ppi/edges.tsv\",\n",
    "    sources_column=\"subject\",\n",
    "    destinations_column=\"object\",\n",
    "    directed=False,\n",
    "    weights_column=\"weight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing, we plot a short report showing all the avalable graph details, including the number of edges, nodes, trap nodes and both the connected components and the strongly connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degrees_mode': '1',\n",
       " 'is_directed': 'false',\n",
       " 'unique_node_types_number': '0',\n",
       " 'density': '0.001993564869255138',\n",
       " 'strongly_connected_components_number': '181',\n",
       " 'connected_components_number': '181',\n",
       " 'unique_edge_types_number': '0',\n",
       " 'traps_rate': '0',\n",
       " 'singleton_nodes': '0',\n",
       " 'selfloops_percentage': '0',\n",
       " 'degrees_mean': '34.25941227814955',\n",
       " 'bidirectional_percentage': '1',\n",
       " 'degrees_median': '11',\n",
       " 'nodes_number': '17185',\n",
       " 'edges_number': '588748'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the holdouts\n",
    "For every one of these examples, we are going to use two experimental setups.\n",
    "\n",
    "We split the graph into a training and validation components.\n",
    "\n",
    "Particularly, the training partition will have the same number of connected components as the original graph, while the validation may have more.\n",
    "\n",
    "We split the two datasets at $0.8$, as done in [Yue et al.](https://academic.oup.com/bioinformatics/article/36/4/1241/5581350).\n",
    "\n",
    "We are going to us two different experimental setups:\n",
    "\n",
    "- One, based on the [Yue et al.](https://academic.oup.com/bioinformatics/article/36/4/1241/5581350) and [Leskovec et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5108654/) experimental setups, where we completely separate training negatives from validation negatives and leave the validation parts of the graphs (both positives and negatives) as \"holes\" in the graph, neither negative nor positive. This may be slighly sconnected from the real scenario, where we cannot remove from a graph part of the validation edges since they are not known. In particular, the negatives edges used in the validation have the same cardinality as the validation positive edges.\n",
    "\n",
    "**For the context of CBOW or GloVe, both setups are the one and the same. The difference is relevant in SkipGram embedding and LinkPrediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the graph into the two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = graph.connected_holdout(42, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the experimental setup\n",
    "For the experimental setup, we are using walk lengths of $100$ nodes, with batch size (number of walks to be considered in each iteration) of $2^{15} = 32768$.\n",
    "\n",
    "We are going to use 20 walk iterations for each node.\n",
    "\n",
    "We are going to use a window size of $4$, meaning $4$ nodes on the left and right of every central node. \n",
    "\n",
    "Consider that the first *window_size* values on the left and the right of the walks will be trimmed.\n",
    "\n",
    "To generate the walks we will use the parameters $p$ and $q$ equal to $1.0$.\n",
    "\n",
    "The *embedding_size* is $100$. For the glove loss, we are going to use an alpha of $0.75$.\n",
    "\n",
    "We are going to use Nadam as obtimizer. We are going to use an Early Stopping criterion on the *validation loss*, with patience $5$ and delta $0.0001$.\n",
    "\n",
    "The model will be trained up to $1000$ epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2**15\n",
    "embedding_size=100\n",
    "iterations=20\n",
    "window_size=4\n",
    "p=1.0\n",
    "q=1.0\n",
    "patience=5\n",
    "delta=0.0001\n",
    "batches_per_epoch = 2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network for Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_prediction_model(embedding_size:int):\n",
    "    model = Sequential([\n",
    "        Inp\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare experimental setup for Leskovec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare new experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
